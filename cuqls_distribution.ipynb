{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ef46b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functorch import make_functional\n",
    "from torch.func import functional_call, vmap, jacrev, jvp\n",
    "    ## NUQLS\n",
    "import posteriors.nuqls as nuqls\n",
    "from importlib import reload\n",
    "reload(nuqls)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tqdm\n",
    "\n",
    "class toy_dataset(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "class variable_mlp(torch.nn.Module):\n",
    "    def __init__(self,layer_width,nonlin):\n",
    "        super().__init__()\n",
    "        self.layer_width = layer_width\n",
    "        self.linear_layers = torch.nn.ModuleList([torch.nn.Linear(layer_width[i],layer_width[i+1], bias=True) for i in range(len(self.layer_width)-1)])\n",
    "        self.lin_out = torch.nn.Linear(self.layer_width[-1],1, bias=True)\n",
    "        if nonlin=='tanh':\n",
    "            self.act = torch.nn.Tanh()\n",
    "        elif nonlin=='relu':\n",
    "            self.act = torch.nn.ReLU()\n",
    "\n",
    "        for lin in self.linear_layers:\n",
    "            torch.nn.init.normal_(lin.weight, 0, 1)\n",
    "        torch.nn.init.normal_(self.lin_out.weight, 0, 1)\n",
    "\n",
    "    # Return full output of nn\n",
    "    def forward(self,x):\n",
    "        for i, lin in enumerate(self.linear_layers):\n",
    "            x = self.act(lin(x)) / (self.layer_width[i]**0.5)\n",
    "        return self.lin_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "807481bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "d = 5\n",
    "layer_widths = [d,20]\n",
    "nonlin = 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e6f4cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn loss : 0.1147\n",
      "\n",
      "-----------------\n",
      "Epoch 0 of 100\n",
      "max l2 loss = 0.171140132178374\n",
      "Residual of normal equation l2 = 66.43049008736743\n",
      "\n",
      "-----------------\n",
      "Epoch 10 of 100\n",
      "max l2 loss = 0.15094746597356123\n",
      "Residual of normal equation l2 = 36.23925029642465\n",
      "\n",
      "-----------------\n",
      "Epoch 20 of 100\n",
      "max l2 loss = 0.13980772999655647\n",
      "Residual of normal equation l2 = 20.333203677402793\n",
      "\n",
      "-----------------\n",
      "Epoch 30 of 100\n",
      "max l2 loss = 0.13345945120752165\n",
      "Residual of normal equation l2 = 11.854384749783945\n",
      "\n",
      "-----------------\n",
      "Epoch 40 of 100\n",
      "max l2 loss = 0.12968237052121956\n",
      "Residual of normal equation l2 = 7.257818476934101\n",
      "\n",
      "-----------------\n",
      "Epoch 50 of 100\n",
      "max l2 loss = 0.12731239100211658\n",
      "Residual of normal equation l2 = 4.706451255743707\n",
      "\n",
      "-----------------\n",
      "Epoch 60 of 100\n",
      "max l2 loss = 0.1257335254787276\n",
      "Residual of normal equation l2 = 3.244755265614347\n",
      "\n",
      "-----------------\n",
      "Epoch 70 of 100\n",
      "max l2 loss = 0.12461548944378933\n",
      "Residual of normal equation l2 = 2.373002238494821\n",
      "\n",
      "-----------------\n",
      "Epoch 80 of 100\n",
      "max l2 loss = 0.12377788246235844\n",
      "Residual of normal equation l2 = 1.8277595188485185\n",
      "\n",
      "-----------------\n",
      "Epoch 90 of 100\n",
      "max l2 loss = 0.1231196705566812\n",
      "Residual of normal equation l2 = 1.468570788272124\n",
      "cuqls loss : 0.1226, resid: 1.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s4531973\\AppData\\Local\\Temp\\ipykernel_14360\\3518632468.py:19: FutureWarning: We've integrated functorch into PyTorch. As the final step of the integration, `functorch.make_functional` is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use `torch.func.functional_call` instead; see the PyTorch 2.0 release notes and/or the `torch.func` migration guide for more details https://pytorch.org/docs/main/func.migrating.html\n",
      "  fnet, params = make_functional(net)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn((n,d))\n",
    "Y = torch.randn((n,1))\n",
    "\n",
    "X_test = torch.randn((n,d))\n",
    "\n",
    "net = variable_mlp(layer_width=layer_widths,nonlin=nonlin)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.1,momentum=0.9)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "for i in range(5000):\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(X)\n",
    "        loss = loss_fn(pred,Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(f'nn loss : {loss.item():.4}')\n",
    "\n",
    "# Compute NTKGP\n",
    "fnet, params = make_functional(net)\n",
    "train_data = toy_dataset(X,Y)\n",
    "test_data = toy_dataset(X_test,Y)\n",
    "\n",
    "nuql = nuqls.small_regression_parallel_width(net, train=train_data, S = 10, epochs=100, lr=0.01, bs=n, bs_test=n, width=layer_widths[-1], init_scale=0.1)\n",
    "loss,resid = nuql.train_linear(mu=0,weight_decay=0,my=0,sy=1,threshold=None,verbose=True, progress_bar=False)\n",
    "nuql_test_preds = nuql.test_linear(test=test_data)\n",
    "print(f'cuqls loss : {loss.item():.4}, resid: {resid.item():.4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e613d4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8533e+00, -2.8282e+00, -3.0499e+00, -2.8780e+00, -3.0864e+00,\n",
       "         -2.7528e+00, -2.9497e+00, -2.8749e+00, -2.8151e+00, -2.7828e+00],\n",
       "        [-3.0797e+00, -3.0206e+00, -2.8722e+00, -2.9797e+00, -2.9706e+00,\n",
       "         -3.0470e+00, -3.1822e+00, -2.9610e+00, -3.0396e+00, -2.9097e+00],\n",
       "        [-1.8688e+00, -1.8718e+00, -1.9400e+00, -1.8867e+00, -1.8595e+00,\n",
       "         -2.1044e+00, -2.0652e+00, -2.0570e+00, -1.9594e+00, -1.8543e+00],\n",
       "        [-2.1421e+00, -2.0711e+00, -2.1153e+00, -2.2527e+00, -2.2065e+00,\n",
       "         -1.9830e+00, -2.0545e+00, -2.1593e+00, -2.1605e+00, -2.2915e+00],\n",
       "        [-1.1083e-01,  1.4973e-02, -4.2185e-02,  1.9202e-02,  7.3365e-03,\n",
       "          8.4283e-02,  1.1332e-01,  1.9734e-01, -4.6046e-02,  1.6546e-01],\n",
       "        [ 3.4585e+00,  3.5403e+00,  3.6417e+00,  3.5730e+00,  3.7155e+00,\n",
       "          3.4660e+00,  3.6503e+00,  3.5354e+00,  3.5289e+00,  3.5700e+00],\n",
       "        [-1.0016e+00, -1.0440e+00, -1.1570e+00, -1.0084e+00, -9.9891e-01,\n",
       "         -9.9917e-01, -8.8161e-01, -1.0020e+00, -9.6137e-01, -1.0265e+00],\n",
       "        [ 1.8231e+00,  1.8018e+00,  1.8088e+00,  1.7779e+00,  1.8925e+00,\n",
       "          1.9000e+00,  1.7397e+00,  1.9217e+00,  1.7682e+00,  2.0347e+00],\n",
       "        [ 4.0183e+00,  3.9387e+00,  3.8368e+00,  3.9927e+00,  3.7054e+00,\n",
       "          4.0072e+00,  3.9187e+00,  3.9922e+00,  3.8809e+00,  3.9643e+00],\n",
       "        [ 2.2857e+00,  2.2438e+00,  2.1658e+00,  2.2097e+00,  2.1886e+00,\n",
       "          2.2302e+00,  2.1559e+00,  2.1981e+00,  2.3587e+00,  2.0441e+00],\n",
       "        [ 5.2903e+00,  5.2380e+00,  5.2931e+00,  5.1781e+00,  5.2792e+00,\n",
       "          5.2447e+00,  5.1864e+00,  5.3046e+00,  5.1022e+00,  5.2970e+00],\n",
       "        [-2.2814e+00, -2.2817e+00, -2.3318e+00, -2.3509e+00, -2.3750e+00,\n",
       "         -2.2780e+00, -2.3876e+00, -2.2564e+00, -2.2905e+00, -2.2957e+00],\n",
       "        [-2.5444e+00, -2.7229e+00, -2.5402e+00, -2.4813e+00, -2.7235e+00,\n",
       "         -2.6974e+00, -2.6471e+00, -2.5693e+00, -2.6134e+00, -2.7903e+00],\n",
       "        [-1.5659e+00, -1.5781e+00, -1.4780e+00, -1.5394e+00, -1.5683e+00,\n",
       "         -1.6969e+00, -1.6912e+00, -1.7006e+00, -1.7851e+00, -1.5953e+00],\n",
       "        [-1.0448e+00, -1.2414e+00, -1.0950e+00, -1.1618e+00, -1.2078e+00,\n",
       "         -1.3610e+00, -1.1539e+00, -1.3889e+00, -1.1952e+00, -1.0500e+00],\n",
       "        [-3.8186e+00, -3.8153e+00, -3.7955e+00, -3.7205e+00, -3.8108e+00,\n",
       "         -3.8691e+00, -3.7534e+00, -3.9590e+00, -3.8533e+00, -3.8987e+00],\n",
       "        [-3.7792e+00, -3.6655e+00, -3.7337e+00, -3.7611e+00, -3.7128e+00,\n",
       "         -3.6873e+00, -3.6947e+00, -3.6956e+00, -3.5284e+00, -3.7792e+00],\n",
       "        [ 7.7421e-02,  2.2736e-01,  1.8023e-01,  1.9321e-01,  1.7427e-01,\n",
       "          2.4922e-01, -1.2051e-03,  2.4553e-01,  3.0021e-02,  1.9020e-01],\n",
       "        [ 4.2770e+00,  4.1410e+00,  4.1858e+00,  4.4139e+00,  4.3518e+00,\n",
       "          4.3165e+00,  4.4013e+00,  4.2727e+00,  4.2435e+00,  4.2093e+00],\n",
       "        [-3.9114e+00, -3.8097e+00, -3.7684e+00, -3.8230e+00, -3.7797e+00,\n",
       "         -3.9435e+00, -3.7279e+00, -3.7954e+00, -3.8586e+00, -3.9078e+00]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuql.theta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
